# üî¥ PLANO DE CORRE√á√ÉO - VULNERABILIDADES CR√çTICAS

**Projeto**: Lumiz Backend
**Data**: 2026-01-13
**Status**: üî¥ N√ÉO PRONTO PARA PRODU√á√ÉO
**Prazo Estimado**: 2-3 semanas (com dedica√ß√£o full-time)

---

## üìã RESUMO EXECUTIVO

Este documento detalha o plano de a√ß√£o para corrigir **6 vulnerabilidades cr√≠ticas** identificadas no backend do Lumiz. Estas vulnerabilidades BLOQUEIAM a libera√ß√£o do sistema para usu√°rios reais.

**Vulnerabilidades Cr√≠ticas:**
1. üî¥ Debug logging vazando dados (31 inst√¢ncias)
2. üî¥ Credenciais expostas em arquivo .env
3. üî¥ RLS (Row Level Security) n√£o configurado
4. üî¥ Autentica√ß√£o fraca (fallback telefone)
5. üî¥ Webhook sem valida√ß√£o de assinatura
6. üî¥ Uploads sem valida√ß√£o

**Risco se n√£o corrigir**: Vazamento de dados financeiros, acesso n√£o autorizado, viola√ß√£o LGPD, responsabilidade legal.

---

## üéØ PRIORIZA√á√ÉO

```
BLOCO 1 (Urgente - Dia 1-3): #1, #2
  ‚Ü≥ Remove vazamentos ativos + protege credenciais

BLOCO 2 (Cr√≠tico - Dia 4-7): #3, #4
  ‚Ü≥ Isola dados entre usu√°rios + fortalece auth

BLOCO 3 (Importante - Dia 8-10): #5, #6
  ‚Ü≥ Protege endpoints p√∫blicos

BLOCO 4 (Valida√ß√£o - Dia 11-15): Testes + documenta√ß√£o
```

---

## üî¥ VULNERABILIDADE #1: Debug Logging Vazando Dados

### Descri√ß√£o do Problema
```javascript
// Encontrado em 31 locais do c√≥digo
fetch('http://127.0.0.1:7242/ingest/59a99cd5-7421-4f77-be12-78a36db4788f', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    location: 'messageController.js:60',
    message: 'Calling processOnboarding',
    data: { phone: normalizedPhone, message }, // üî¥ DADOS SENS√çVEIS!
    timestamp: Date.now()
  })
}).catch(() => {});
```

**Impacto**:
- Dados sens√≠veis (telefone, mensagens, transa√ß√µes) sendo enviados para endpoint externo
- Em produ√ß√£o, vai tentar conectar a localhost e falhar (gastando recursos)
- Pode ser usado para rastrear comportamento de usu√°rios

**Arquivos Afetados** (31 inst√¢ncias):
- `src/controllers/messageController.js` (2x)
- `src/controllers/messageController.refactored.js` (2x)
- `src/services/onboardingFlowService.js` (2x)
- `src/controllers/messages/documentHandler.js` (3x)
- `src/controllers/messages/editHandler.js` (3x)
- `src/controllers/messages/exportHandler.js` (3x)
- `src/controllers/messages/goalHandler.js` (3x)
- `src/controllers/messages/helpHandler.js` (2x)
- `src/controllers/messages/insightsHandler.js` (3x)
- `src/controllers/messages/installmentHandler.js` (2x)
- `src/controllers/messages/queryHandler.js` (2x)
- `src/controllers/messages/scheduleHandler.js` (2x)
- `src/controllers/messages/searchHandler.js` (2x)
- `src/controllers/messages/transactionHandler.js` (2x)

### Plano de Corre√ß√£o

#### PASSO 1: Criar script de remo√ß√£o automatizada
```bash
# Script: scripts/remove-debug-fetch.sh
#!/bin/bash

echo "üîç Procurando inst√¢ncias de debug fetch..."

# Encontrar todos os arquivos com fetch para localhost:7242
FILES=$(grep -r "fetch('http://127.0.0.1:7242" src/ -l)

echo "üìù Arquivos encontrados:"
echo "$FILES"

# Contar inst√¢ncias
COUNT=$(grep -r "fetch('http://127.0.0.1:7242" src/ | wc -l)
echo "üìä Total de inst√¢ncias: $COUNT"

# Backup
echo "üíæ Criando backup..."
mkdir -p .backup/$(date +%Y%m%d_%H%M%S)
for file in $FILES; do
  cp "$file" ".backup/$(date +%Y%m%d_%H%M%S)/"
done

echo "‚úÖ Backup criado em .backup/"
echo ""
echo "‚ö†Ô∏è  Execute o script de remo√ß√£o manualmente ou revise cada arquivo"
```

#### PASSO 2: Padr√µes de remo√ß√£o

**Padr√£o 1**: Fetch completo (mais comum)
```javascript
// üî¥ REMOVER:
fetch('http://127.0.0.1:7242/ingest/59a99cd5-7421-4f77-be12-78a36db4788f', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    location: 'messageController.js:60',
    message: 'Calling processOnboarding',
    data: { phone: normalizedPhone, message },
    timestamp: Date.now(),
    sessionId: 'debug-session',
    runId: 'run1',
    hypothesisId: 'A'
  })
}).catch(() => {});

// ‚úÖ SUBSTITUIR POR: (nada - remover completamente)
```

**Padr√£o 2**: Fetch com vari√°veis
```javascript
// üî¥ REMOVER:
const debugData = {
  location: 'file.js:123',
  data: someData
};
fetch('http://127.0.0.1:7242/ingest/...', {
  body: JSON.stringify(debugData)
}).catch(() => {});

// ‚úÖ SUBSTITUIR POR: (nada)
```

**Padr√£o 3**: Se precisar debug em desenvolvimento
```javascript
// ‚úÖ ALTERNATIVA (se realmente precisar):
if (process.env.NODE_ENV === 'development' && process.env.DEBUG_ENDPOINT) {
  logger.debug('Debug info', {
    location: 'messageController.js:60',
    data: { phone: '***REDACTED***', messageLength: message.length }
  });
}
```

#### PASSO 3: Script de remo√ß√£o automatizado

```bash
# Script: scripts/fix-debug-fetch.js
const fs = require('fs');
const path = require('path');
const glob = require('glob');

// Regex para encontrar fetch debug
const DEBUG_FETCH_REGEX = /fetch\(['"]http:\/\/127\.0\.0\.1:7242[^)]+\)\s*\.catch\([^)]*\)\s*;?/gs;

// Encontrar todos os arquivos
const files = glob.sync('src/**/*.js');

let totalRemoved = 0;

files.forEach(file => {
  const content = fs.readFileSync(file, 'utf8');
  const matches = content.match(DEBUG_FETCH_REGEX);

  if (matches) {
    console.log(`üìù Processando: ${file} (${matches.length} inst√¢ncias)`);

    // Remover fetches
    const newContent = content.replace(DEBUG_FETCH_REGEX, '');

    // Salvar
    fs.writeFileSync(file, newContent, 'utf8');

    totalRemoved += matches.length;
    console.log(`   ‚úÖ Removidas ${matches.length} inst√¢ncias`);
  }
});

console.log(`\n‚úÖ Total removido: ${totalRemoved} inst√¢ncias`);
```

#### PASSO 4: Valida√ß√£o

```bash
# 1. Executar remo√ß√£o
node scripts/fix-debug-fetch.js

# 2. Verificar que n√£o restaram inst√¢ncias
grep -r "fetch('http://127.0.0.1:7242" src/
# Deve retornar: (nada)

# 3. Verificar que c√≥digo ainda compila
npm run lint
npm test

# 4. Verificar git diff
git diff src/ | grep -A 5 -B 5 "fetch"
```

#### PASSO 5: Preven√ß√£o futura

```javascript
// .eslintrc.js - adicionar regra
module.exports = {
  rules: {
    'no-restricted-syntax': [
      'error',
      {
        selector: "CallExpression[callee.name='fetch'] Literal[value=/127\\.0\\.0\\.1/]",
        message: 'üî¥ N√£o use fetch para localhost em c√≥digo de produ√ß√£o. Use logger.debug()'
      }
    ]
  }
};
```

### Checklist de Valida√ß√£o

- [ ] Backup dos arquivos criado
- [ ] Script de remo√ß√£o executado
- [ ] Verificado que 0 inst√¢ncias restam (`grep -r "127.0.0.1:7242"`)
- [ ] C√≥digo compila sem erros (`npm run build`)
- [ ] Testes passam (`npm test`)
- [ ] ESLint regra adicionada para prevenir
- [ ] Commit das mudan√ßas
- [ ] Deploy em staging e verificar logs

**Tempo Estimado**: 2-4 horas

---

## üî¥ VULNERABILIDADE #2: Credenciais Expostas em .env

### Descri√ß√£o do Problema

```bash
# .env (NUNCA deve ser versionado!)
EVOLUTION_API_KEY=4C7B62D0F0CD-4D1A-82E0-31F68E056A60
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
GEMINI_API_KEY=AIzaSyCt0-6YOs7V8p_o7JcdYtxc75-5T9UbMTk
GOOGLE_VISION_API_KEY=AIzaSyDgoqVaiYdQPxlpK3o__6NVpdaBRcrpocM
REDIS_URL=redis://default:cOobifPnpRQzKfbxfOFVcadPaApiiZda@redis...
```

**Impacto**:
- ‚úó Service Role Key = acesso TOTAL ao banco de dados
- ‚úó Gemini API Key = custos ilimitados na sua conta Google
- ‚úó Evolution API Key = controle do WhatsApp
- ‚úó Se reposit√≥rio vazou, credenciais est√£o comprometidas

### Plano de Corre√ß√£o

#### PASSO 1: Verificar se .env est√° no reposit√≥rio

```bash
# Verificar se .env foi commitado
git log --all --full-history -- .env

# Se retornar algo = üî¥ FOI COMMITADO!
# Se n√£o retornar nada = ‚úÖ Nunca foi commitado
```

#### PASSO 2A: Se .env FOI commitado (üî¥ CR√çTICO)

```bash
# 1. ROTACIONAR TODAS AS CREDENCIAIS IMEDIATAMENTE
echo "üî¥ CREDENCIAIS COMPROMETIDAS - ROTACIONAR AGORA!"

# 2. Remover .env do hist√≥rico completo do git
git filter-branch --force --index-filter \
  "git rm --cached --ignore-unmatch .env" \
  --prune-empty --tag-name-filter cat -- --all

# 3. For√ßar push (CUIDADO - coordenar com time)
git push origin --force --all
git push origin --force --tags

# 4. Limpar reflog local
rm -rf .git/refs/original/
git reflog expire --expire=now --all
git gc --prune=now --aggressive
```

**ATEN√á√ÉO**: Se o reposit√≥rio √© p√∫blico ou foi clonado por outras pessoas, considere as credenciais PERMANENTEMENTE comprometidas.

#### PASSO 2B: Se .env NUNCA foi commitado (‚úÖ Melhor cen√°rio)

```bash
# Apenas garantir que est√° no .gitignore
echo ".env" >> .gitignore
echo ".env.*" >> .gitignore
echo "!.env.example" >> .gitignore

git add .gitignore
git commit -m "chore: adiciona .env ao .gitignore"
```

#### PASSO 3: Criar arquivo .env.example (template)

```bash
# .env.example (pode ser versionado)
# Railway: Configure estas vari√°veis no Dashboard -> Variables

# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key_here

# Evolution API (WhatsApp)
EVOLUTION_API_URL=https://your-evolution-api.com
EVOLUTION_API_KEY=your_evolution_key_here
EVOLUTION_INSTANCE_NAME=your_instance_name

# Google APIs
GEMINI_API_KEY=your_gemini_key_here
GOOGLE_VISION_API_KEY=your_vision_key_here

# Redis (opcional - usa mem√≥ria se n√£o configurado)
REDIS_URL=redis://user:password@host:6379

# Seguran√ßa
CRON_SECRET=generate_random_secret_here

# Node
NODE_ENV=production
PORT=3000
LOG_LEVEL=info
```

#### PASSO 4: Configurar vari√°veis no Railway

```bash
# 1. Acessar Railway Dashboard
# https://railway.app/project/<seu-projeto>/variables

# 2. Adicionar TODAS as vari√°veis do .env.example

# 3. Usar Railway CLI (alternativa)
railway variables set SUPABASE_URL "https://..."
railway variables set SUPABASE_SERVICE_ROLE_KEY "eyJ..."
railway variables set EVOLUTION_API_KEY "4C7..."
railway variables set GEMINI_API_KEY "AIza..."
railway variables set GOOGLE_VISION_API_KEY "AIza..."
railway variables set CRON_SECRET "$(openssl rand -hex 32)"
```

#### PASSO 5: ROTACIONAR todas as credenciais

##### 5.1 - Supabase Service Role Key

```bash
# 1. Acessar Supabase Dashboard
# https://supabase.com/dashboard/project/<seu-projeto>/settings/api

# 2. Gerar nova Service Role Key
# ‚ö†Ô∏è ATEN√á√ÉO: Isso vai invalidar a chave antiga!

# 3. Atualizar no Railway
railway variables set SUPABASE_SERVICE_ROLE_KEY "nova_chave_aqui"

# 4. Reiniciar aplica√ß√£o
railway up
```

##### 5.2 - Evolution API Key

```bash
# 1. Acessar Evolution API Dashboard
# 2. Gerar nova API Key
# 3. Atualizar no Railway
railway variables set EVOLUTION_API_KEY "nova_chave_aqui"
```

##### 5.3 - Google Gemini API Key

```bash
# 1. Acessar Google Cloud Console
# https://console.cloud.google.com/apis/credentials

# 2. Revogar chave antiga
# 3. Criar nova API Key
# 4. Restringir a API Key (IP whitelist se poss√≠vel)
# 5. Atualizar no Railway
railway variables set GEMINI_API_KEY "nova_chave_aqui"
```

##### 5.4 - Google Vision API Key

```bash
# Mesmo processo do Gemini
# 1. Revogar chave antiga
# 2. Criar nova
# 3. Restringir
# 4. Atualizar Railway
railway variables set GOOGLE_VISION_API_KEY "nova_chave_aqui"
```

##### 5.5 - CRON Secret (gerar novo)

```bash
# Gerar secret forte
CRON_SECRET=$(openssl rand -hex 32)
echo "Novo CRON_SECRET: $CRON_SECRET"

# Atualizar Railway
railway variables set CRON_SECRET "$CRON_SECRET"
```

#### PASSO 6: Atualizar c√≥digo para validar vari√°veis

```javascript
// src/config/env.js - MELHORAR valida√ß√£o

class EnvValidator {
  validate() {
    const required = [
      'SUPABASE_URL',
      'SUPABASE_SERVICE_ROLE_KEY',
      'EVOLUTION_API_URL',
      'EVOLUTION_API_KEY',
      'EVOLUTION_INSTANCE_NAME',
      'CRON_SECRET' // üî¥ Agora obrigat√≥rio!
    ];

    const missing = required.filter(key => !process.env[key]);

    if (missing.length > 0) {
      console.error('üî¥ ERRO: Vari√°veis obrigat√≥rias faltando:');
      missing.forEach(key => console.error(`   - ${key}`));

      // üî¥ SEMPRE falhar se vari√°veis cr√≠ticas faltam
      if (process.env.NODE_ENV === 'production') {
        console.error('üî¥ Produ√ß√£o requer todas as vari√°veis. Abortando.');
        process.exit(1);
      }

      return { valid: false, missing };
    }

    // Validar formato de URLs
    try {
      new URL(process.env.SUPABASE_URL);
      new URL(process.env.EVOLUTION_API_URL);
    } catch (err) {
      console.error('üî¥ ERRO: URL inv√°lida', err.message);
      process.exit(1);
    }

    // Validar comprimento de secrets
    if (process.env.CRON_SECRET.length < 32) {
      console.error('üî¥ ERRO: CRON_SECRET muito curto (m√≠nimo 32 caracteres)');
      process.exit(1);
    }

    console.log('‚úÖ Todas as vari√°veis de ambiente validadas');
    return { valid: true };
  }
}

module.exports = new EnvValidator();
```

#### PASSO 7: Documentar processo para time

```markdown
# README.md - adicionar se√ß√£o

## üîê Configura√ß√£o de Vari√°veis de Ambiente

### Desenvolvimento Local

1. Copie o arquivo de exemplo:
   ```bash
   cp .env.example .env
   ```

2. Preencha as vari√°veis no `.env` com suas credenciais de desenvolvimento

3. **NUNCA comite o arquivo `.env`**

### Produ√ß√£o (Railway)

1. Configure as vari√°veis no Railway Dashboard:
   - Project ‚Üí Variables

2. Vari√°veis obrigat√≥rias:
   - `SUPABASE_URL`
   - `SUPABASE_SERVICE_ROLE_KEY`
   - `EVOLUTION_API_KEY`
   - `GEMINI_API_KEY`
   - `CRON_SECRET` (gere com: `openssl rand -hex 32`)

### Rota√ß√£o de Credenciais

Rotacione as credenciais a cada 90 dias ou imediatamente se houver suspeita de vazamento.
```

#### PASSO 8: Setup de Secrets Scanning (GitHub)

```yaml
# .github/workflows/secrets-scan.yml
name: Secrets Scanning

on: [push, pull_request]

jobs:
  scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0 # Pega hist√≥rico completo

      - name: Run Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

### Checklist de Valida√ß√£o

- [ ] Verificado se .env foi commitado (git log)
- [ ] Se sim: removido do hist√≥rico + credenciais rotacionadas
- [ ] .env adicionado ao .gitignore
- [ ] .env.example criado e commitado
- [ ] Todas as vari√°veis configuradas no Railway
- [ ] TODAS as credenciais rotacionadas (Supabase, Google, Evolution, CRON)
- [ ] C√≥digo atualizado para validar vari√°veis obrigat√≥rias
- [ ] CRON_SECRET agora √© obrigat√≥rio
- [ ] Documenta√ß√£o atualizada
- [ ] Secrets scanning configurado (GitHub Actions)
- [ ] Time notificado sobre novas credenciais
- [ ] Deploy testado em staging
- [ ] Confirmado que aplica√ß√£o inicia sem .env local (s√≥ Railway vars)

**Tempo Estimado**: 3-6 horas (incluindo rota√ß√£o de credenciais)

**CR√çTICO**: Se .env foi commitado em reposit√≥rio P√öBLICO, considere TODAS as credenciais permanentemente comprometidas e tome a√ß√µes adicionais de seguran√ßa.

---

## üî¥ VULNERABILIDADE #3: RLS (Row Level Security) N√£o Configurado

### Descri√ß√£o do Problema

```sql
-- Estado atual: SEM RLS
-- Usu√°rio A pode acessar dados do usu√°rio B

SELECT * FROM atendimentos;
-- ‚ö†Ô∏è Retorna TODOS os atendimentos de TODOS os usu√°rios!

SELECT * FROM contas_pagar;
-- ‚ö†Ô∏è Retorna TODAS as despesas de TODOS os usu√°rios!
```

**Impacto**:
- ‚úó Viola√ß√£o cr√≠tica de privacidade
- ‚úó Vazamento de dados financeiros
- ‚úó N√£o compliance com LGPD
- ‚úó Qualquer usu√°rio v√™ dados de outros

**Evid√™ncia**: Migrations de RLS foram deletadas do git
```bash
D  supabase/migrations/20251216000000_enable_rls_security.sql
D  supabase/migrations/20251216000001_fix_sql_functions_security.sql
```

### Plano de Corre√ß√£o

#### PASSO 1: Recuperar migrations deletadas

```bash
# Tentar recuperar do hist√≥rico git
git log --all --full-history -- supabase/migrations/*rls*.sql

# Se existir, recuperar
git show <commit-hash>:supabase/migrations/20251216000000_enable_rls_security.sql > supabase/migrations/20251216000000_enable_rls_security.sql
```

#### PASSO 2: Se migrations n√£o existem, criar do zero

```sql
-- supabase/migrations/20260113000000_enable_rls_security.sql

-- ============================================================================
-- HABILITAR RLS EM TODAS AS TABELAS
-- ============================================================================

-- Tabela: profiles
ALTER TABLE profiles ENABLE ROW LEVEL SECURITY;

-- Tabela: atendimentos (receitas/vendas)
ALTER TABLE atendimentos ENABLE ROW LEVEL SECURITY;

-- Tabela: contas_pagar (despesas)
ALTER TABLE contas_pagar ENABLE ROW LEVEL SECURITY;

-- Tabela: clientes
ALTER TABLE clientes ENABLE ROW LEVEL SECURITY;

-- Tabela: procedimentos
ALTER TABLE procedimentos ENABLE ROW LEVEL SECURITY;

-- Tabela: onboarding_progress
ALTER TABLE onboarding_progress ENABLE ROW LEVEL SECURITY;

-- Tabela: mdr_configs
ALTER TABLE mdr_configs ENABLE ROW LEVEL SECURITY;

-- Tabela: ocr_jobs
ALTER TABLE ocr_jobs ENABLE ROW LEVEL SECURITY;

-- Tabela: user_insights
ALTER TABLE user_insights ENABLE ROW LEVEL SECURITY;

-- Tabela: analytics_events
ALTER TABLE analytics_events ENABLE ROW LEVEL SECURITY;

-- ============================================================================
-- POLICIES: profiles
-- ============================================================================

-- Usu√°rio pode ver apenas seu pr√≥prio perfil
CREATE POLICY "Usu√°rios podem ver pr√≥prio perfil"
  ON profiles FOR SELECT
  USING (auth.uid() = id);

-- Usu√°rio pode atualizar apenas seu pr√≥prio perfil
CREATE POLICY "Usu√°rios podem atualizar pr√≥prio perfil"
  ON profiles FOR UPDATE
  USING (auth.uid() = id);

-- Service role pode ver tudo (necess√°rio para backend)
CREATE POLICY "Service role acesso total profiles"
  ON profiles FOR ALL
  USING (auth.jwt()->>'role' = 'service_role');

-- ============================================================================
-- POLICIES: atendimentos (receitas)
-- ============================================================================

-- Usu√°rio v√™ apenas seus atendimentos
CREATE POLICY "Usu√°rios veem pr√≥prios atendimentos"
  ON atendimentos FOR SELECT
  USING (profile_id = auth.uid());

-- Usu√°rio pode inserir atendimentos para si
CREATE POLICY "Usu√°rios inserem pr√≥prios atendimentos"
  ON atendimentos FOR INSERT
  WITH CHECK (profile_id = auth.uid());

-- Usu√°rio pode atualizar apenas seus atendimentos
CREATE POLICY "Usu√°rios atualizam pr√≥prios atendimentos"
  ON atendimentos FOR UPDATE
  USING (profile_id = auth.uid());

-- Usu√°rio pode deletar apenas seus atendimentos
CREATE POLICY "Usu√°rios deletam pr√≥prios atendimentos"
  ON atendimentos FOR DELETE
  USING (profile_id = auth.uid());

-- Service role acesso total
CREATE POLICY "Service role acesso total atendimentos"
  ON atendimentos FOR ALL
  USING (auth.jwt()->>'role' = 'service_role');

-- ============================================================================
-- POLICIES: contas_pagar (despesas)
-- ============================================================================

CREATE POLICY "Usu√°rios veem pr√≥prias contas"
  ON contas_pagar FOR SELECT
  USING (profile_id = auth.uid());

CREATE POLICY "Usu√°rios inserem pr√≥prias contas"
  ON contas_pagar FOR INSERT
  WITH CHECK (profile_id = auth.uid());

CREATE POLICY "Usu√°rios atualizam pr√≥prias contas"
  ON contas_pagar FOR UPDATE
  USING (profile_id = auth.uid());

CREATE POLICY "Usu√°rios deletam pr√≥prias contas"
  ON contas_agar FOR DELETE
  USING (profile_id = auth.uid());

CREATE POLICY "Service role acesso total contas_pagar"
  ON contas_pagar FOR ALL
  USING (auth.jwt()->>'role' = 'service_role');

-- ============================================================================
-- POLICIES: clientes
-- ============================================================================

CREATE POLICY "Usu√°rios veem pr√≥prios clientes"
  ON clientes FOR SELECT
  USING (profile_id = auth.uid());

CREATE POLICY "Usu√°rios inserem pr√≥prios clientes"
  ON clientes FOR INSERT
  WITH CHECK (profile_id = auth.uid());

CREATE POLICY "Usu√°rios atualizam pr√≥prios clientes"
  ON clientes FOR UPDATE
  USING (profile_id = auth.uid());

CREATE POLICY "Usu√°rios deletam pr√≥prios clientes"
  ON clientes FOR DELETE
  USING (profile_id = auth.uid());

CREATE POLICY "Service role acesso total clientes"
  ON clientes FOR ALL
  USING (auth.jwt()->>'role' = 'service_role');

-- ============================================================================
-- POLICIES: procedimentos
-- ============================================================================

CREATE POLICY "Usu√°rios veem pr√≥prios procedimentos"
  ON procedimentos FOR SELECT
  USING (profile_id = auth.uid());

CREATE POLICY "Usu√°rios inserem pr√≥prios procedimentos"
  ON procedimentos FOR INSERT
  WITH CHECK (profile_id = auth.uid());

CREATE POLICY "Usu√°rios atualizam pr√≥prios procedimentos"
  ON procedimentos FOR UPDATE
  USING (profile_id = auth.uid());

CREATE POLICY "Usu√°rios deletam pr√≥prios procedimentos"
  ON procedimentos FOR DELETE
  USING (profile_id = auth.uid());

CREATE POLICY "Service role acesso total procedimentos"
  ON procedimentos FOR ALL
  USING (auth.jwt()->>'role' = 'service_role');

-- ============================================================================
-- POLICIES: onboarding_progress
-- ============================================================================

-- Usu√°rio v√™ apenas seu onboarding (via phone que mapeia para profile_id)
CREATE POLICY "Usu√°rios veem pr√≥prio onboarding"
  ON onboarding_progress FOR SELECT
  USING (
    EXISTS (
      SELECT 1 FROM profiles
      WHERE profiles.id = auth.uid()
      AND profiles.phone = onboarding_progress.phone
    )
  );

CREATE POLICY "Usu√°rios atualizam pr√≥prio onboarding"
  ON onboarding_progress FOR UPDATE
  USING (
    EXISTS (
      SELECT 1 FROM profiles
      WHERE profiles.id = auth.uid()
      AND profiles.phone = onboarding_progress.phone
    )
  );

CREATE POLICY "Service role acesso total onboarding"
  ON onboarding_progress FOR ALL
  USING (auth.jwt()->>'role' = 'service_role');

-- ============================================================================
-- POLICIES: mdr_configs
-- ============================================================================

CREATE POLICY "Usu√°rios veem pr√≥prias configs MDR"
  ON mdr_configs FOR SELECT
  USING (profile_id = auth.uid());

CREATE POLICY "Usu√°rios inserem pr√≥prias configs MDR"
  ON mdr_configs FOR INSERT
  WITH CHECK (profile_id = auth.uid());

CREATE POLICY "Usu√°rios atualizam pr√≥prias configs MDR"
  ON mdr_configs FOR UPDATE
  USING (profile_id = auth.uid());

CREATE POLICY "Service role acesso total mdr_configs"
  ON mdr_configs FOR ALL
  USING (auth.jwt()->>'role' = 'service_role');

-- ============================================================================
-- POLICIES: ocr_jobs
-- ============================================================================

CREATE POLICY "Usu√°rios veem pr√≥prios OCR jobs"
  ON ocr_jobs FOR SELECT
  USING (profile_id = auth.uid());

CREATE POLICY "Service role acesso total ocr_jobs"
  ON ocr_jobs FOR ALL
  USING (auth.jwt()->>'role' = 'service_role');

-- ============================================================================
-- POLICIES: user_insights
-- ============================================================================

CREATE POLICY "Usu√°rios veem pr√≥prios insights"
  ON user_insights FOR SELECT
  USING (profile_id = auth.uid());

CREATE POLICY "Service role acesso total insights"
  ON user_insights FOR ALL
  USING (auth.jwt()->>'role' = 'service_role');

-- ============================================================================
-- POLICIES: analytics_events
-- ============================================================================

CREATE POLICY "Usu√°rios veem pr√≥prios eventos"
  ON analytics_events FOR SELECT
  USING (profile_id = auth.uid());

CREATE POLICY "Service role acesso total analytics"
  ON analytics_events FOR ALL
  USING (auth.jwt()->>'role' = 'service_role');

-- ============================================================================
-- VERIFICA√á√ÉO FINAL
-- ============================================================================

-- Lista todas as tabelas e status de RLS
SELECT
  schemaname,
  tablename,
  rowsecurity as rls_enabled
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY tablename;

-- Lista todas as policies criadas
SELECT
  schemaname,
  tablename,
  policyname,
  permissive,
  roles,
  cmd,
  qual,
  with_check
FROM pg_policies
WHERE schemaname = 'public'
ORDER BY tablename, policyname;
```

#### PASSO 3: Aplicar migration

```bash
# 1. Via Supabase CLI (recomendado)
npx supabase db push

# 2. Via interface Supabase (alternativa)
# Dashboard ‚Üí SQL Editor ‚Üí Cole o SQL ‚Üí Run

# 3. Via script Node.js
node scripts/apply-migrations.js
```

#### PASSO 4: Criar script de verifica√ß√£o de RLS

```javascript
// scripts/verify-rls.js

const { createClient } = require('@supabase/supabase-js');

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

async function verifyRLS() {
  console.log('üîç Verificando RLS...\n');

  // Lista de tabelas que devem ter RLS
  const tables = [
    'profiles',
    'atendimentos',
    'contas_pagar',
    'clientes',
    'procedimentos',
    'onboarding_progress',
    'mdr_configs',
    'ocr_jobs',
    'user_insights',
    'analytics_events'
  ];

  // Verificar status RLS
  const { data: rlsStatus, error: rlsError } = await supabase
    .from('pg_tables')
    .select('tablename, rowsecurity')
    .eq('schemaname', 'public')
    .in('tablename', tables);

  if (rlsError) {
    console.error('‚ùå Erro ao verificar RLS:', rlsError);
    process.exit(1);
  }

  console.log('üìä Status de RLS por tabela:\n');
  let allEnabled = true;

  rlsStatus.forEach(table => {
    const status = table.rowsecurity ? '‚úÖ' : '‚ùå';
    console.log(`${status} ${table.tablename}: ${table.rowsecurity ? 'ATIVO' : 'DESABILITADO'}`);
    if (!table.rowsecurity) allEnabled = false;
  });

  // Verificar policies
  const { data: policies, error: polError } = await supabase
    .from('pg_policies')
    .select('tablename, policyname, cmd')
    .eq('schemaname', 'public')
    .in('tablename', tables);

  console.log('\nüìã Policies por tabela:\n');
  tables.forEach(table => {
    const tablePolicies = policies.filter(p => p.tablename === table);
    console.log(`${table}: ${tablePolicies.length} policies`);
    tablePolicies.forEach(p => {
      console.log(`  - ${p.policyname} (${p.cmd})`);
    });
  });

  if (allEnabled) {
    console.log('\n‚úÖ RLS est√° ativo em todas as tabelas!');
    process.exit(0);
  } else {
    console.log('\n‚ùå ERRO: RLS n√£o est√° ativo em todas as tabelas');
    process.exit(1);
  }
}

verifyRLS();
```

#### PASSO 5: Teste de vazamento de dados

```javascript
// scripts/test-rls.js

const { createClient } = require('@supabase/supabase-js');

async function testRLS() {
  console.log('üß™ Testando RLS...\n');

  // Criar 2 usu√°rios de teste
  const supabaseAdmin = createClient(
    process.env.SUPABASE_URL,
    process.env.SUPABASE_SERVICE_ROLE_KEY
  );

  // 1. Criar usu√°rio A e inserir dados
  const { data: userA, error: errA } = await supabaseAdmin.auth.admin.createUser({
    email: 'test_user_a@example.com',
    password: 'test123',
    email_confirm: true
  });

  const supabaseA = createClient(
    process.env.SUPABASE_URL,
    process.env.SUPABASE_ANON_KEY
  );

  await supabaseA.auth.signInWithPassword({
    email: 'test_user_a@example.com',
    password: 'test123'
  });

  // Inserir atendimento para usu√°rio A
  const { data: atendA } = await supabaseA
    .from('atendimentos')
    .insert({
      profile_id: userA.user.id,
      valor: 1000,
      descricao: 'Atendimento privado de A'
    })
    .select()
    .single();

  console.log('‚úÖ Usu√°rio A criado e dados inseridos');

  // 2. Criar usu√°rio B e tentar acessar dados de A
  const { data: userB } = await supabaseAdmin.auth.admin.createUser({
    email: 'test_user_b@example.com',
    password: 'test123',
    email_confirm: true
  });

  const supabaseB = createClient(
    process.env.SUPABASE_URL,
    process.env.SUPABASE_ANON_KEY
  );

  await supabaseB.auth.signInWithPassword({
    email: 'test_user_b@example.com',
    password: 'test123'
  });

  // Tentar ler atendimento de A como usu√°rio B
  const { data: leakedData } = await supabaseB
    .from('atendimentos')
    .select('*')
    .eq('id', atendA.id);

  if (leakedData && leakedData.length > 0) {
    console.log('‚ùå FALHA: Usu√°rio B conseguiu ler dados de usu√°rio A!');
    console.log('   Dados vazados:', leakedData);
    process.exit(1);
  } else {
    console.log('‚úÖ SUCESSO: Usu√°rio B N√ÉO conseguiu ler dados de usu√°rio A');
  }

  // 3. Verificar que usu√°rio B v√™ apenas seus dados
  await supabaseB
    .from('atendimentos')
    .insert({
      profile_id: userB.user.id,
      valor: 2000,
      descricao: 'Atendimento privado de B'
    });

  const { data: dataB } = await supabaseB
    .from('atendimentos')
    .select('*');

  if (dataB.length === 1 && dataB[0].profile_id === userB.user.id) {
    console.log('‚úÖ SUCESSO: Usu√°rio B v√™ apenas seus pr√≥prios dados');
  } else {
    console.log('‚ùå FALHA: Usu√°rio B est√° vendo dados de outros usu√°rios');
    process.exit(1);
  }

  // Cleanup
  await supabaseAdmin.auth.admin.deleteUser(userA.user.id);
  await supabaseAdmin.auth.admin.deleteUser(userB.user.id);

  console.log('\n‚úÖ Todos os testes de RLS passaram!');
}

testRLS();
```

#### PASSO 6: Atualizar c√≥digo backend para usar auth correto

```javascript
// src/middleware/authMiddleware.js

// ‚ùå REMOVER authenticateFlexible (permite telefone sem token)

// ‚úÖ MANTER APENAS authenticate (obriga token JWT)
const authenticate = async (req, res, next) => {
  try {
    const authHeader = req.headers.authorization;

    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return res.status(401).json({ error: 'Token n√£o fornecido' });
    }

    const token = authHeader.split(' ')[1];

    // Verificar token com Supabase
    const { data: { user }, error } = await supabase.auth.getUser(token);

    if (error || !user) {
      return res.status(401).json({ error: 'Token inv√°lido' });
    }

    // Buscar perfil completo
    const { data: profile, error: profileError } = await supabase
      .from('profiles')
      .select('*')
      .eq('id', user.id)
      .single();

    if (profileError) {
      return res.status(401).json({ error: 'Perfil n√£o encontrado' });
    }

    req.user = profile;
    next();
  } catch (error) {
    logger.error('Erro na autentica√ß√£o', { error });
    return res.status(401).json({ error: 'Falha na autentica√ß√£o' });
  }
};

// ‚úÖ Para webhook (que n√£o tem usu√°rio), criar middleware espec√≠fico
const authenticateWebhook = async (req, res, next) => {
  // Validar signature HMAC (ver vulnerabilidade #5)
  const signature = req.headers['x-evolution-signature'];

  if (!validateSignature(req.body, signature)) {
    return res.status(401).json({ error: 'Signature inv√°lida' });
  }

  next();
};

module.exports = { authenticate, authenticateWebhook };
```

### Checklist de Valida√ß√£o

- [ ] Migration de RLS criada ou recuperada
- [ ] Migration aplicada no Supabase
- [ ] Script de verifica√ß√£o executado (verify-rls.js)
- [ ] Todas as tabelas t√™m RLS ativo
- [ ] Todas as tabelas t√™m policies criadas
- [ ] Teste de vazamento executado (test-rls.js)
- [ ] Confirmado que usu√°rio B N√ÉO v√™ dados de usu√°rio A
- [ ] C√≥digo backend atualizado (removido authenticateFlexible)
- [ ] Todas as rotas usam authenticate correto
- [ ] Deploy em staging testado
- [ ] Teste manual com 2 contas reais
- [ ] Documenta√ß√£o atualizada

**Tempo Estimado**: 4-8 horas (incluindo testes extensivos)

---

## üî¥ VULNERABILIDADE #4: Autentica√ß√£o Fraca (Fallback Telefone)

### Descri√ß√£o do Problema

```javascript
// src/middleware/authMiddleware.js
const authenticateFlexible = async (req, res, next) => {
  // Tenta token JWT primeiro
  if (authHeader) {
    // ... valida√ß√£o JWT
  }

  // ‚ùå FALLBACK PERIGOSO: aceita apenas telefone
  const phone = req.headers['x-user-phone'] || req.query.phone;

  if (phone) {
    const { data: profile } = await supabase
      .from('profiles')
      .select('*')
      .eq('phone', phone)
      .maybeSingle();

    if (profile) {
      req.user = profile;
      return next(); // ‚úÖ Autenticado SEM senha!
    }
  }
};
```

**Impacto**:
- ‚úó Qualquer pessoa que saiba o telefone de um usu√°rio pode se passar por ele
- ‚úó Basta enviar header `X-User-Phone: +5511999999999`
- ‚úó Zero prova de identidade
- ‚úó Viola LGPD (acesso n√£o autorizado a dados pessoais)

### Plano de Corre√ß√£o

#### PASSO 1: Remover authenticateFlexible completamente

```javascript
// src/middleware/authMiddleware.js

// ‚ùå DELETAR ESTA FUN√á√ÉO:
// const authenticateFlexible = async (req, res, next) => { ... }

// ‚úÖ MANTER APENAS:
const authenticate = async (req, res, next) => {
  try {
    const authHeader = req.headers.authorization;

    // 1. Token √© OBRIGAT√ìRIO
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      logger.warn('Tentativa de acesso sem token', {
        ip: req.ip,
        path: req.path
      });
      return res.status(401).json({
        error: 'Autentica√ß√£o necess√°ria',
        code: 'NO_TOKEN'
      });
    }

    const token = authHeader.split(' ')[1];

    // 2. Validar token com Supabase
    const { data: { user }, error: authError } = await supabase.auth.getUser(token);

    if (authError || !user) {
      logger.warn('Token inv√°lido', {
        error: authError?.message,
        ip: req.ip
      });
      return res.status(401).json({
        error: 'Token inv√°lido ou expirado',
        code: 'INVALID_TOKEN'
      });
    }

    // 3. Buscar perfil completo (com RLS ativo, s√≥ vai retornar se for o pr√≥prio)
    const { data: profile, error: profileError } = await supabase
      .from('profiles')
      .select('*')
      .eq('id', user.id)
      .single();

    if (profileError || !profile) {
      logger.error('Perfil n√£o encontrado', {
        userId: user.id,
        error: profileError
      });
      return res.status(404).json({
        error: 'Perfil n√£o encontrado',
        code: 'PROFILE_NOT_FOUND'
      });
    }

    // 4. Anexar usu√°rio na request
    req.user = profile;
    req.auth = { userId: user.id, token };

    next();
  } catch (error) {
    logger.error('Erro na autentica√ß√£o', {
      error: error.message,
      stack: error.stack,
      ip: req.ip
    });
    return res.status(500).json({
      error: 'Falha na autentica√ß√£o',
      code: 'AUTH_ERROR'
    });
  }
};

module.exports = { authenticate };
```

#### PASSO 2: Criar middleware separado para webhook (sem usu√°rio)

```javascript
// src/middleware/webhookAuth.js

const crypto = require('crypto');
const logger = require('../config/logger');

/**
 * Middleware de autentica√ß√£o para webhook da Evolution API
 * Valida signature HMAC para garantir origem leg√≠tima
 */
const authenticateWebhook = (req, res, next) => {
  try {
    // 1. Verificar se tem signature header
    const signature = req.headers['x-evolution-signature'];

    if (!signature) {
      logger.warn('Webhook sem signature', {
        ip: req.ip,
        headers: req.headers
      });
      return res.status(401).json({
        error: 'Signature n√£o fornecida',
        code: 'NO_SIGNATURE'
      });
    }

    // 2. Recalcular signature com o body
    const webhookSecret = process.env.EVOLUTION_WEBHOOK_SECRET;

    if (!webhookSecret) {
      logger.error('EVOLUTION_WEBHOOK_SECRET n√£o configurado!');
      return res.status(500).json({
        error: 'Configura√ß√£o inv√°lida',
        code: 'CONFIG_ERROR'
      });
    }

    const payload = JSON.stringify(req.body);
    const expectedSignature = crypto
      .createHmac('sha256', webhookSecret)
      .update(payload)
      .digest('hex');

    // 3. Comparar signatures (timing-safe)
    const isValid = crypto.timingSafeEqual(
      Buffer.from(signature),
      Buffer.from(expectedSignature)
    );

    if (!isValid) {
      logger.warn('Webhook com signature inv√°lida', {
        ip: req.ip,
        receivedSignature: signature.substring(0, 10) + '...',
        expectedSignature: expectedSignature.substring(0, 10) + '...'
      });
      return res.status(401).json({
        error: 'Signature inv√°lida',
        code: 'INVALID_SIGNATURE'
      });
    }

    // 4. Signature v√°lida - prosseguir
    logger.debug('Webhook autenticado', { ip: req.ip });
    next();
  } catch (error) {
    logger.error('Erro ao validar webhook', {
      error: error.message,
      stack: error.stack
    });
    return res.status(500).json({
      error: 'Falha na valida√ß√£o',
      code: 'VALIDATION_ERROR'
    });
  }
};

module.exports = { authenticateWebhook };
```

#### PASSO 3: Atualizar rotas que usavam authenticateFlexible

```javascript
// src/routes/dashboard.js

// ‚ùå ANTES:
router.get('/stats', authenticateFlexible, getDashboardStats);

// ‚úÖ DEPOIS:
router.get('/stats', authenticate, getDashboardStats);
```

```javascript
// src/routes/onboarding.js

// ‚ùå ANTES:
router.get('/status', authenticateFlexible, getOnboardingStatus);

// ‚úÖ DEPOIS:
router.get('/status', authenticate, getOnboardingStatus);
```

```javascript
// src/routes/user.js

// ‚ùå ANTES:
router.get('/profile', authenticateFlexible, getUserProfile);

// ‚úÖ DEPOIS:
router.get('/profile', authenticate, getUserProfile);
```

```javascript
// src/routes/webhook.js

// ‚ùå ANTES: Sem autentica√ß√£o
app.post('/api/webhook', async (req, res) => { ... });

// ‚úÖ DEPOIS: Com valida√ß√£o de signature
const { authenticateWebhook } = require('../middleware/webhookAuth');

app.post('/api/webhook', authenticateWebhook, async (req, res) => { ... });
```

#### PASSO 4: Buscar TODAS as refer√™ncias a authenticateFlexible

```bash
# Encontrar todas as ocorr√™ncias
grep -r "authenticateFlexible" src/

# Deve retornar:
# src/middleware/authMiddleware.js (defini√ß√£o)
# src/routes/*.js (v√°rios usos)

# Substituir TODAS por authenticate
```

#### PASSO 5: Adicionar testes de autentica√ß√£o

```javascript
// tests/auth.test.js

const request = require('supertest');
const app = require('../src/server');

describe('Authentication Middleware', () => {

  test('‚ùå Deve rejeitar requisi√ß√£o sem token', async () => {
    const res = await request(app)
      .get('/api/dashboard/stats')
      .expect(401);

    expect(res.body.code).toBe('NO_TOKEN');
  });

  test('‚ùå Deve rejeitar token inv√°lido', async () => {
    const res = await request(app)
      .get('/api/dashboard/stats')
      .set('Authorization', 'Bearer invalid_token_here')
      .expect(401);

    expect(res.body.code).toBe('INVALID_TOKEN');
  });

  test('‚ùå Deve rejeitar telefone no header (sem token)', async () => {
    const res = await request(app)
      .get('/api/dashboard/stats')
      .set('X-User-Phone', '+5511999999999')
      .expect(401);

    expect(res.body.code).toBe('NO_TOKEN');
  });

  test('‚úÖ Deve aceitar token JWT v√°lido', async () => {
    // Criar usu√°rio de teste e pegar token
    const { token } = await createTestUser();

    const res = await request(app)
      .get('/api/dashboard/stats')
      .set('Authorization', `Bearer ${token}`)
      .expect(200);

    expect(res.body).toHaveProperty('stats');
  });

  test('‚ùå Webhook sem signature deve ser rejeitado', async () => {
    const res = await request(app)
      .post('/api/webhook')
      .send({ message: 'test' })
      .expect(401);

    expect(res.body.code).toBe('NO_SIGNATURE');
  });

  test('‚ùå Webhook com signature inv√°lida deve ser rejeitado', async () => {
    const res = await request(app)
      .post('/api/webhook')
      .set('X-Evolution-Signature', 'invalid_signature')
      .send({ message: 'test' })
      .expect(401);

    expect(res.body.code).toBe('INVALID_SIGNATURE');
  });

  test('‚úÖ Webhook com signature v√°lida deve ser aceito', async () => {
    const payload = { message: 'test' };
    const signature = generateValidSignature(payload);

    const res = await request(app)
      .post('/api/webhook')
      .set('X-Evolution-Signature', signature)
      .send(payload)
      .expect(200);
  });
});
```

#### PASSO 6: Configurar EVOLUTION_WEBHOOK_SECRET na Evolution API

```bash
# 1. Gerar secret forte
WEBHOOK_SECRET=$(openssl rand -hex 32)
echo "EVOLUTION_WEBHOOK_SECRET=$WEBHOOK_SECRET"

# 2. Configurar no Railway
railway variables set EVOLUTION_WEBHOOK_SECRET "$WEBHOOK_SECRET"

# 3. Configurar na Evolution API
# Docs: https://doc.evolution-api.com/v2/pt/integrate/webhook#autenticacao

# Via API:
curl -X POST https://your-evolution-api.com/webhook/config \
  -H "apikey: $EVOLUTION_API_KEY" \
  -d '{
    "url": "https://your-backend.railway.app/api/webhook",
    "enabled": true,
    "webhook_by_events": false,
    "events": ["messages.upsert"],
    "webhook_base64": false,
    "secret": "'$WEBHOOK_SECRET'"
  }'

# Via Dashboard Evolution API:
# Settings ‚Üí Webhook ‚Üí Secret: [cole o secret]
```

### Checklist de Valida√ß√£o

- [ ] authenticateFlexible deletado de authMiddleware.js
- [ ] authenticate (obrigat√≥rio JWT) implementado
- [ ] authenticateWebhook criado com valida√ß√£o HMAC
- [ ] Todas as rotas dashboard/* usam authenticate
- [ ] Todas as rotas onboarding/* usam authenticate
- [ ] Todas as rotas user/* usam authenticate
- [ ] Webhook usa authenticateWebhook
- [ ] EVOLUTION_WEBHOOK_SECRET gerado e configurado
- [ ] Evolution API configurada com secret
- [ ] Testes de autentica√ß√£o criados e passando
- [ ] Teste manual: requisi√ß√£o sem token √© rejeitada
- [ ] Teste manual: requisi√ß√£o com telefone √© rejeitada
- [ ] Teste manual: webhook sem signature √© rejeitado
- [ ] Deploy em staging testado
- [ ] Documenta√ß√£o atualizada

**Tempo Estimado**: 3-5 horas

---

## üî¥ VULNERABILIDADE #5: Webhook Sem Valida√ß√£o de Assinatura

### Descri√ß√£o do Problema

```javascript
// src/routes/webhook.js

// ‚ùå VULNER√ÅVEL: Aceita de qualquer origem
app.post('/api/webhook', async (req, res) => {
  const body = req.body; // Processa diretamente

  // Qualquer pessoa pode enviar:
  // curl -X POST https://your-api.com/api/webhook \
  //   -H "Content-Type: application/json" \
  //   -d '{"message": "fake message", "from": "any_user"}'
});
```

**Impacto**:
- ‚úó Qualquer pessoa pode enviar mensagens falsas
- ‚úó Pode se passar por qualquer usu√°rio
- ‚úó Pode injetar comandos maliciosos
- ‚úó DoS via flood de mensagens

**Solu√ß√£o**: J√° foi coberta na vulnerabilidade #4 (authenticateWebhook). Vou complementar aqui com configura√ß√£o da Evolution API.

### Plano de Corre√ß√£o (Complementar)

#### PASSO 1: Configurar webhook na Evolution API

```javascript
// scripts/setup-evolution-webhook.js

const axios = require('axios');

async function setupWebhook() {
  const config = {
    url: process.env.WEBHOOK_URL || 'https://your-backend.railway.app/api/webhook',
    enabled: true,
    webhook_by_events: true,
    webhook_base64: false, // N√£o enviar base64 no webhook (economiza banda)
    events: [
      'messages.upsert',    // Nova mensagem
      'messages.update',    // Mensagem editada
      'messages.delete',    // Mensagem deletada
      'connection.update'   // Status da conex√£o
    ],
    secret: process.env.EVOLUTION_WEBHOOK_SECRET
  };

  try {
    const response = await axios.post(
      `${process.env.EVOLUTION_API_URL}/webhook/${process.env.EVOLUTION_INSTANCE_NAME}`,
      config,
      {
        headers: {
          'apikey': process.env.EVOLUTION_API_KEY,
          'Content-Type': 'application/json'
        }
      }
    );

    console.log('‚úÖ Webhook configurado com sucesso!');
    console.log('Config:', response.data);
  } catch (error) {
    console.error('‚ùå Erro ao configurar webhook:', error.response?.data || error.message);
    process.exit(1);
  }
}

setupWebhook();
```

#### PASSO 2: Validar configura√ß√£o do webhook

```javascript
// scripts/verify-evolution-webhook.js

const axios = require('axios');
const crypto = require('crypto');

async function verifyWebhook() {
  try {
    // 1. Verificar configura√ß√£o
    const response = await axios.get(
      `${process.env.EVOLUTION_API_URL}/webhook/${process.env.EVOLUTION_INSTANCE_NAME}`,
      {
        headers: {
          'apikey': process.env.EVOLUTION_API_KEY
        }
      }
    );

    const config = response.data;
    console.log('üìã Configura√ß√£o atual do webhook:');
    console.log('  URL:', config.url);
    console.log('  Enabled:', config.enabled);
    console.log('  Events:', config.events);
    console.log('  Has Secret:', !!config.secret);

    // 2. Verificar se secret est√° configurado
    if (!config.secret) {
      console.log('\n‚ùå ERRO: Webhook sem secret!');
      console.log('Execute: node scripts/setup-evolution-webhook.js');
      process.exit(1);
    }

    // 3. Verificar se secret √© o mesmo
    if (config.secret !== process.env.EVOLUTION_WEBHOOK_SECRET) {
      console.log('\n‚ö†Ô∏è  AVISO: Secret no Evolution n√£o confere com .env');
      console.log('Execute: node scripts/setup-evolution-webhook.js');
      process.exit(1);
    }

    console.log('\n‚úÖ Webhook configurado corretamente!');
  } catch (error) {
    console.error('‚ùå Erro:', error.response?.data || error.message);
    process.exit(1);
  }
}

verifyWebhook();
```

#### PASSO 3: Teste de seguran√ßa do webhook

```javascript
// tests/webhook-security.test.js

const request = require('supertest');
const crypto = require('crypto');
const app = require('../src/server');

describe('Webhook Security', () => {

  test('‚ùå Deve rejeitar webhook sem signature', async () => {
    const res = await request(app)
      .post('/api/webhook')
      .send({
        event: 'messages.upsert',
        data: { message: 'test' }
      })
      .expect(401);

    expect(res.body.code).toBe('NO_SIGNATURE');
  });

  test('‚ùå Deve rejeitar webhook com signature inv√°lida', async () => {
    const res = await request(app)
      .post('/api/webhook')
      .set('X-Evolution-Signature', 'invalid_sig')
      .send({
        event: 'messages.upsert',
        data: { message: 'test' }
      })
      .expect(401);

    expect(res.body.code).toBe('INVALID_SIGNATURE');
  });

  test('‚ùå Deve rejeitar webhook com signature de body diferente', async () => {
    const originalBody = { event: 'messages.upsert', data: { message: 'original' } };
    const tamperedBody = { event: 'messages.upsert', data: { message: 'tampered' } };

    // Gerar signature do body original
    const signature = crypto
      .createHmac('sha256', process.env.EVOLUTION_WEBHOOK_SECRET)
      .update(JSON.stringify(originalBody))
      .digest('hex');

    // Enviar body adulterado
    const res = await request(app)
      .post('/api/webhook')
      .set('X-Evolution-Signature', signature)
      .send(tamperedBody)
      .expect(401);

    expect(res.body.code).toBe('INVALID_SIGNATURE');
  });

  test('‚úÖ Deve aceitar webhook com signature v√°lida', async () => {
    const body = {
      event: 'messages.upsert',
      instance: 'test-instance',
      data: {
        key: { remoteJid: '5511999999999@s.whatsapp.net' },
        message: { conversation: 'Hello' }
      }
    };

    const signature = crypto
      .createHmac('sha256', process.env.EVOLUTION_WEBHOOK_SECRET)
      .update(JSON.stringify(body))
      .digest('hex');

    const res = await request(app)
      .post('/api/webhook')
      .set('X-Evolution-Signature', signature)
      .send(body)
      .expect(200);
  });

  test('‚ùå Deve detectar timing attack na compara√ß√£o de signature', async () => {
    // Teste de timing-safe comparison
    const body = { test: 'data' };
    const correctSig = crypto
      .createHmac('sha256', process.env.EVOLUTION_WEBHOOK_SECRET)
      .update(JSON.stringify(body))
      .digest('hex');

    const almostCorrectSig = correctSig.substring(0, correctSig.length - 1) + 'X';

    const start = process.hrtime.bigint();
    await request(app)
      .post('/api/webhook')
      .set('X-Evolution-Signature', almostCorrectSig)
      .send(body);
    const end = process.hrtime.bigint();

    const timeDiff = Number(end - start) / 1000000; // ms

    // Timing deve ser constante (< 10ms varia√ß√£o)
    // Se > 100ms, pode ter timing leak
    expect(timeDiff).toBeLessThan(100);
  });
});
```

#### PASSO 4: Rate limiting espec√≠fico para webhook

```javascript
// src/middleware/webhookRateLimit.js

const rateLimit = require('express-rate-limit');
const RedisStore = require('rate-limit-redis');
const Redis = require('ioredis');
const logger = require('../config/logger');

// Limitar webhook por IP (prevenir flood)
const webhookRateLimit = rateLimit({
  store: process.env.REDIS_URL ? new RedisStore({
    client: new Redis(process.env.REDIS_URL),
    prefix: 'webhook_rl:'
  }) : undefined,

  windowMs: 1 * 60 * 1000, // 1 minuto
  max: 60, // 60 requisi√ß√µes por minuto = 1/segundo

  message: {
    error: 'Muitas requisi√ß√µes ao webhook',
    code: 'RATE_LIMIT_EXCEEDED'
  },

  standardHeaders: true,
  legacyHeaders: false,

  handler: (req, res) => {
    logger.warn('Webhook rate limit excedido', {
      ip: req.ip,
      headers: req.headers
    });
    res.status(429).json({
      error: 'Muitas requisi√ß√µes',
      code: 'RATE_LIMIT_EXCEEDED'
    });
  }
});

module.exports = { webhookRateLimit };
```

```javascript
// src/routes/webhook.js

const { authenticateWebhook } = require('../middleware/webhookAuth');
const { webhookRateLimit } = require('../middleware/webhookRateLimit');

// Aplicar rate limit E autentica√ß√£o
app.post('/api/webhook',
  webhookRateLimit,        // 1. Rate limit primeiro
  authenticateWebhook,     // 2. Depois autentica√ß√£o
  async (req, res) => {    // 3. Processar
    // ...
  }
);
```

### Checklist de Valida√ß√£o

- [ ] authenticateWebhook implementado (ver vulnerabilidade #4)
- [ ] EVOLUTION_WEBHOOK_SECRET configurado
- [ ] Script setup-evolution-webhook.js executado
- [ ] Evolution API configurada com secret
- [ ] Script verify-evolution-webhook.js executado e passou
- [ ] Webhook rate limiting configurado
- [ ] Testes de seguran√ßa criados e passando
- [ ] Teste timing-safe comparison
- [ ] Teste manual: webhook sem signature rejeitado
- [ ] Teste manual: webhook com signature v√°lida aceito
- [ ] Deploy em staging testado
- [ ] Webhook real da Evolution API funcionando

**Tempo Estimado**: 2-3 horas (j√° coberto na #4, s√≥ configura√ß√£o)

---

## üî¥ VULNERABILIDADE #6: Uploads Sem Valida√ß√£o

### Descri√ß√£o do Problema

```javascript
// src/routes/webhook.js

// ‚ùå VULNER√ÅVEL:
app.use(express.json({ limit: '10mb' })); // Aceita at√© 10MB

// webhook.js
const base64Data = message.imageMessage?.base64;
if (base64Data) {
  const imageBuffer = Buffer.from(base64Data, 'base64'); // SEM valida√ß√£o!
  // Envia para Google Vision...
}

// mdrOcrService.js
async downloadImage(imageUrl) {
  const res = await axios.get(imageUrl, { // ‚ùå URL n√£o validada
    responseType: 'arraybuffer'
  });
  return Buffer.from(res.data);
}
```

**Impacto**:
- ‚úó DoS via imagens gigantes (10MB * muitos usu√°rios)
- ‚úó SSRF via URL maliciosa (acessar rede interna)
- ‚úó Poss√≠vel RCE via exploits de processamento de imagem
- ‚úó Custos Google Vision (processar imagens maliciosas)

### Plano de Corre√ß√£o

#### PASSO 1: Criar middleware de valida√ß√£o de imagens

```javascript
// src/middleware/imageValidation.js

const sharp = require('sharp');
const logger = require('../config/logger');

// Tipos MIME permitidos
const ALLOWED_MIME_TYPES = [
  'image/jpeg',
  'image/jpg',
  'image/png',
  'image/webp'
];

// Limites
const MAX_FILE_SIZE = 5 * 1024 * 1024; // 5MB
const MAX_DIMENSION = 4096; // 4096x4096 pixels
const MIN_DIMENSION = 50; // 50x50 pixels

/**
 * Valida buffer de imagem
 */
async function validateImageBuffer(buffer, context = {}) {
  try {
    // 1. Verificar tamanho
    if (buffer.length > MAX_FILE_SIZE) {
      logger.warn('Imagem muito grande', {
        size: buffer.length,
        maxSize: MAX_FILE_SIZE,
        ...context
      });
      throw new Error(`Imagem muito grande (m√°ximo ${MAX_FILE_SIZE / 1024 / 1024}MB)`);
    }

    // 2. Verificar se √© realmente uma imagem (usando sharp)
    let metadata;
    try {
      metadata = await sharp(buffer).metadata();
    } catch (err) {
      logger.warn('Arquivo n√£o √© uma imagem v√°lida', {
        error: err.message,
        ...context
      });
      throw new Error('Arquivo n√£o √© uma imagem v√°lida');
    }

    // 3. Verificar MIME type
    const mimeType = `image/${metadata.format}`;
    if (!ALLOWED_MIME_TYPES.includes(mimeType)) {
      logger.warn('Tipo de imagem n√£o permitido', {
        mimeType,
        allowed: ALLOWED_MIME_TYPES,
        ...context
      });
      throw new Error(`Tipo n√£o permitido (permitidos: ${ALLOWED_MIME_TYPES.join(', ')})`);
    }

    // 4. Verificar dimens√µes
    if (metadata.width > MAX_DIMENSION || metadata.height > MAX_DIMENSION) {
      logger.warn('Dimens√µes da imagem muito grandes', {
        width: metadata.width,
        height: metadata.height,
        max: MAX_DIMENSION,
        ...context
      });
      throw new Error(`Dimens√µes muito grandes (m√°ximo ${MAX_DIMENSION}x${MAX_DIMENSION})`);
    }

    if (metadata.width < MIN_DIMENSION || metadata.height < MIN_DIMENSION) {
      logger.warn('Dimens√µes da imagem muito pequenas', {
        width: metadata.width,
        height: metadata.height,
        min: MIN_DIMENSION,
        ...context
      });
      throw new Error(`Dimens√µes muito pequenas (m√≠nimo ${MIN_DIMENSION}x${MIN_DIMENSION})`);
    }

    // 5. Verificar se tem m√∫ltiplas p√°ginas (potencial exploit)
    if (metadata.pages && metadata.pages > 1) {
      logger.warn('Imagem com m√∫ltiplas p√°ginas', {
        pages: metadata.pages,
        ...context
      });
      throw new Error('Imagens com m√∫ltiplas p√°ginas n√£o s√£o permitidas');
    }

    // 6. Sanitizar: reprocessar imagem para remover metadados/exploits
    const sanitized = await sharp(buffer)
      .removeAlpha() // Remove canal alpha
      .jpeg({ quality: 90 }) // Reconverter para JPEG
      .toBuffer();

    logger.info('Imagem validada com sucesso', {
      originalSize: buffer.length,
      sanitizedSize: sanitized.length,
      dimensions: `${metadata.width}x${metadata.height}`,
      format: metadata.format,
      ...context
    });

    return {
      valid: true,
      buffer: sanitized,
      metadata: {
        width: metadata.width,
        height: metadata.height,
        format: metadata.format,
        size: sanitized.length
      }
    };
  } catch (error) {
    return {
      valid: false,
      error: error.message
    };
  }
}

/**
 * Valida base64 de imagem
 */
async function validateBase64Image(base64Data, context = {}) {
  try {
    // 1. Verificar tamanho antes de decodificar
    const estimatedSize = (base64Data.length * 3) / 4;
    if (estimatedSize > MAX_FILE_SIZE) {
      throw new Error('Base64 muito grande');
    }

    // 2. Decodificar
    const buffer = Buffer.from(base64Data, 'base64');

    // 3. Validar buffer
    return await validateImageBuffer(buffer, context);
  } catch (error) {
    return {
      valid: false,
      error: error.message
    };
  }
}

/**
 * Valida URL de imagem (anti-SSRF)
 */
function validateImageUrl(url) {
  try {
    const parsed = new URL(url);

    // 1. Apenas HTTPS
    if (parsed.protocol !== 'https:') {
      throw new Error('Apenas URLs HTTPS s√£o permitidas');
    }

    // 2. Blacklist de IPs internos
    const hostname = parsed.hostname.toLowerCase();

    // IPs privados
    const privatePatterns = [
      /^localhost$/i,
      /^127\.\d+\.\d+\.\d+$/,
      /^10\.\d+\.\d+\.\d+$/,
      /^172\.(1[6-9]|2\d|3[01])\.\d+\.\d+$/,
      /^192\.168\.\d+\.\d+$/,
      /^169\.254\.\d+\.\d+$/, // Link-local
      /^::1$/, // IPv6 localhost
      /^fe80:/i, // IPv6 link-local
      /^fc00:/i, // IPv6 private
    ];

    for (const pattern of privatePatterns) {
      if (pattern.test(hostname)) {
        throw new Error('URL aponta para rede privada');
      }
    }

    // 3. Whitelist de dom√≠nios conhecidos (opcional)
    const allowedDomains = [
      'evolution-api.com',
      'githubusercontent.com',
      // Adicionar dom√≠nios confi√°veis
    ];

    const isAllowed = allowedDomains.some(domain =>
      hostname === domain || hostname.endsWith(`.${domain}`)
    );

    if (!isAllowed) {
      logger.warn('URL de dom√≠nio n√£o confi√°vel', { url: hostname });
      // Pode rejeitar ou apenas logar (depende da pol√≠tica)
    }

    return { valid: true, url: parsed.href };
  } catch (error) {
    return {
      valid: false,
      error: error.message
    };
  }
}

module.exports = {
  validateImageBuffer,
  validateBase64Image,
  validateImageUrl,
  MAX_FILE_SIZE,
  MAX_DIMENSION,
  ALLOWED_MIME_TYPES
};
```

#### PASSO 2: Aplicar valida√ß√£o no webhook

```javascript
// src/routes/webhook.js

const { validateBase64Image } = require('../middleware/imageValidation');

app.post('/api/webhook',
  webhookRateLimit,
  authenticateWebhook,
  async (req, res) => {
    try {
      const { message } = extractMessageData(req.body);

      // Se tem imagem, validar
      if (message.imageMessage) {
        const base64Data = message.imageMessage.base64;

        if (base64Data) {
          // ‚úÖ VALIDAR antes de processar
          const validation = await validateBase64Image(base64Data, {
            phone,
            messageId: message.key.id
          });

          if (!validation.valid) {
            logger.warn('Imagem inv√°lida recebida', {
              phone,
              error: validation.error
            });

            // Notificar usu√°rio
            await evolutionApiService.sendMessage(phone,
              '‚ùå Imagem inv√°lida. Por favor, envie uma imagem JPG ou PNG de at√© 5MB.'
            );

            return res.status(200).json({
              success: false,
              error: validation.error
            });
          }

          // Usar buffer sanitizado
          const sanitizedBuffer = validation.buffer;

          // Processar OCR com imagem validada
          await documentHandler.handle(phone, message, sanitizedBuffer);
        }
      }

      // ... resto do processamento

      res.status(200).json({ success: true });
    } catch (error) {
      logger.error('Erro no webhook', { error });
      res.status(500).json({ error: 'Erro ao processar' });
    }
  }
);
```

#### PASSO 3: Aplicar valida√ß√£o no download de URLs

```javascript
// src/services/mdrOcrService.js

const axios = require('axios');
const { validateImageUrl, validateImageBuffer } = require('../middleware/imageValidation');

async downloadImage(imageUrl) {
  // ‚úÖ VALIDAR URL primeiro (anti-SSRF)
  const urlValidation = validateImageUrl(imageUrl);

  if (!urlValidation.valid) {
    logger.error('URL inv√°lida para download', {
      url: imageUrl,
      error: urlValidation.error
    });
    throw new Error(`URL inv√°lida: ${urlValidation.error}`);
  }

  try {
    const response = await axios.get(urlValidation.url, {
      responseType: 'arraybuffer',
      timeout: 10000, // 10s timeout
      maxContentLength: 5 * 1024 * 1024, // 5MB
      maxRedirects: 3,
      headers: {
        'User-Agent': 'LumizBot/1.0'
      }
    });

    const buffer = Buffer.from(response.data);

    // ‚úÖ VALIDAR buffer baixado
    const validation = await validateImageBuffer(buffer, {
      source: 'download',
      url: imageUrl
    });

    if (!validation.valid) {
      throw new Error(`Imagem baixada inv√°lida: ${validation.error}`);
    }

    logger.info('Imagem baixada e validada', {
      url: imageUrl,
      size: validation.metadata.size
    });

    return validation.buffer; // Retorna buffer sanitizado
  } catch (error) {
    if (error.code === 'ECONNREFUSED' || error.code === 'ETIMEDOUT') {
      logger.error('Erro de rede ao baixar imagem', {
        url: imageUrl,
        code: error.code
      });
      throw new Error('N√£o foi poss√≠vel baixar a imagem');
    }
    throw error;
  }
}
```

#### PASSO 4: Rate limiting por usu√°rio para uploads

```javascript
// src/middleware/userRateLimit.js

const rateLimit = require('express-rate-limit');
const RedisStore = require('rate-limit-redis');
const Redis = require('ioredis');

// Rate limit para uploads de imagem por usu√°rio
const imageUploadRateLimit = rateLimit({
  store: process.env.REDIS_URL ? new RedisStore({
    client: new Redis(process.env.REDIS_URL),
    prefix: 'img_rl:'
  }) : undefined,

  windowMs: 15 * 60 * 1000, // 15 minutos
  max: 20, // 20 imagens por 15 minutos

  keyGenerator: (req) => {
    // Rate limit por usu√°rio (n√£o por IP)
    return req.user?.phone || req.ip;
  },

  message: {
    error: 'Voc√™ atingiu o limite de uploads de imagens. Tente novamente em 15 minutos.',
    code: 'IMAGE_RATE_LIMIT'
  },

  handler: (req, res) => {
    logger.warn('Rate limit de imagens excedido', {
      phone: req.user?.phone,
      ip: req.ip
    });
    res.status(429).json({
      error: 'Muitos uploads de imagens',
      code: 'IMAGE_RATE_LIMIT'
    });
  }
});

module.exports = { imageUploadRateLimit };
```

#### PASSO 5: Adicionar testes de valida√ß√£o

```javascript
// tests/image-validation.test.js

const { validateImageBuffer, validateBase64Image, validateImageUrl } = require('../src/middleware/imageValidation');
const fs = require('fs');
const path = require('path');

describe('Image Validation', () => {

  test('‚úÖ Deve aceitar JPEG v√°lido', async () => {
    const buffer = fs.readFileSync(path.join(__dirname, 'fixtures/valid.jpg'));
    const result = await validateImageBuffer(buffer);

    expect(result.valid).toBe(true);
    expect(result.buffer).toBeInstanceOf(Buffer);
    expect(result.metadata.format).toBe('jpeg');
  });

  test('‚úÖ Deve aceitar PNG v√°lido', async () => {
    const buffer = fs.readFileSync(path.join(__dirname, 'fixtures/valid.png'));
    const result = await validateImageBuffer(buffer);

    expect(result.valid).toBe(true);
  });

  test('‚ùå Deve rejeitar arquivo n√£o-imagem', async () => {
    const buffer = Buffer.from('not an image');
    const result = await validateImageBuffer(buffer);

    expect(result.valid).toBe(false);
    expect(result.error).toContain('n√£o √© uma imagem v√°lida');
  });

  test('‚ùå Deve rejeitar imagem muito grande', async () => {
    // Criar buffer de 6MB (acima do limite de 5MB)
    const largeBuffer = Buffer.alloc(6 * 1024 * 1024);
    const result = await validateImageBuffer(largeBuffer);

    expect(result.valid).toBe(false);
    expect(result.error).toContain('muito grande');
  });

  test('‚ùå Deve rejeitar base64 malicioso', async () => {
    const maliciousBase64 = 'A'.repeat(10 * 1024 * 1024); // 10MB de 'A'
    const result = await validateBase64Image(maliciousBase64);

    expect(result.valid).toBe(false);
  });

  test('‚ùå Deve rejeitar URL localhost (SSRF)', () => {
    const result = validateImageUrl('http://localhost:8080/image.jpg');

    expect(result.valid).toBe(false);
    expect(result.error).toContain('privada');
  });

  test('‚ùå Deve rejeitar URL 127.0.0.1 (SSRF)', () => {
    const result = validateImageUrl('https://127.0.0.1/secret');

    expect(result.valid).toBe(false);
  });

  test('‚ùå Deve rejeitar URL rede privada 192.168 (SSRF)', () => {
    const result = validateImageUrl('https://192.168.1.1/admin');

    expect(result.valid).toBe(false);
  });

  test('‚ùå Deve rejeitar URL HTTP (n√£o HTTPS)', () => {
    const result = validateImageUrl('http://example.com/image.jpg');

    expect(result.valid).toBe(false);
    expect(result.error).toContain('HTTPS');
  });

  test('‚úÖ Deve aceitar URL HTTPS p√∫blica', () => {
    const result = validateImageUrl('https://example.com/image.jpg');

    expect(result.valid).toBe(true);
  });

  test('‚úÖ Deve sanitizar imagem (remover metadados)', async () => {
    // Imagem com EXIF data
    const bufferWithExif = fs.readFileSync(path.join(__dirname, 'fixtures/with-exif.jpg'));
    const result = await validateImageBuffer(bufferWithExif);

    expect(result.valid).toBe(true);

    // Buffer sanitizado n√£o deve ter EXIF
    const sharp = require('sharp');
    const metadata = await sharp(result.buffer).metadata();
    expect(metadata.exif).toBeUndefined();
  });
});
```

### Checklist de Valida√ß√£o

- [ ] imageValidation.js criado com todas as valida√ß√µes
- [ ] Valida√ß√£o aplicada no webhook (base64)
- [ ] Valida√ß√£o aplicada no download de URLs
- [ ] Rate limiting de uploads por usu√°rio implementado
- [ ] SSRF prevention testado (localhost, 127.0.0.1, 192.168.x.x)
- [ ] Testes de valida√ß√£o criados e passando
- [ ] Teste com imagem > 5MB (deve rejeitar)
- [ ] Teste com arquivo n√£o-imagem (deve rejeitar)
- [ ] Teste com URL maliciosa (deve rejeitar)
- [ ] Teste com imagem v√°lida (deve aceitar e sanitizar)
- [ ] Deploy em staging testado
- [ ] Teste manual com imagem real via WhatsApp

**Tempo Estimado**: 4-6 horas

---

## üìä RESUMO DO PLANO DE A√á√ÉO

### Cronograma Sugerido

```
SEMANA 1:
‚îú‚îÄ‚îÄ Dia 1-2: Vulnerabilidade #1 (Debug logging) + #2 (Secrets)
‚îÇ   ‚îú‚îÄ‚îÄ Remover 31 inst√¢ncias de fetch debug
‚îÇ   ‚îú‚îÄ‚îÄ Rotacionar TODAS as credenciais
‚îÇ   ‚îî‚îÄ‚îÄ Configurar secrets no Railway
‚îÇ
‚îú‚îÄ‚îÄ Dia 3-4: Vulnerabilidade #3 (RLS)
‚îÇ   ‚îú‚îÄ‚îÄ Criar migrations de RLS
‚îÇ   ‚îú‚îÄ‚îÄ Aplicar no Supabase
‚îÇ   ‚îî‚îÄ‚îÄ Testar isolamento de dados
‚îÇ
‚îî‚îÄ‚îÄ Dia 5: Vulnerabilidade #4 (Auth)
    ‚îú‚îÄ‚îÄ Remover authenticateFlexible
    ‚îú‚îÄ‚îÄ Implementar authenticate obrigat√≥rio
    ‚îî‚îÄ‚îÄ Criar authenticateWebhook

SEMANA 2:
‚îú‚îÄ‚îÄ Dia 1-2: Vulnerabilidade #5 (Webhook) + #6 (Uploads)
‚îÇ   ‚îú‚îÄ‚îÄ Configurar webhook signature
‚îÇ   ‚îú‚îÄ‚îÄ Implementar valida√ß√£o de imagens
‚îÇ   ‚îî‚îÄ‚îÄ Anti-SSRF
‚îÇ
‚îú‚îÄ‚îÄ Dia 3-4: Testes e Valida√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ Executar todos os testes
‚îÇ   ‚îú‚îÄ‚îÄ Testes de seguran√ßa
‚îÇ   ‚îî‚îÄ‚îÄ Testes manuais
‚îÇ
‚îî‚îÄ‚îÄ Dia 5: Deploy e Documenta√ß√£o
    ‚îú‚îÄ‚îÄ Deploy em staging
    ‚îú‚îÄ‚îÄ Testes em produ√ß√£o (canary)
    ‚îî‚îÄ‚îÄ Documenta√ß√£o finalizada
```

### Ordem de Execu√ß√£o

```
BLOCO 1 (Urgente): #1, #2
  ‚Üì
BLOCO 2 (Cr√≠tico): #3, #4
  ‚Üì
BLOCO 3 (Importante): #5, #6
  ‚Üì
BLOCO 4 (Valida√ß√£o): Testes + Deploy
```

### Estimativa de Tempo Total

| Fase | Tempo | Dias |
|------|-------|------|
| Bloco 1 (Debug + Secrets) | 5-10h | 1-2 dias |
| Bloco 2 (RLS + Auth) | 7-13h | 2-3 dias |
| Bloco 3 (Webhook + Uploads) | 6-9h | 2 dias |
| Bloco 4 (Testes + Deploy) | 4-6h | 1-2 dias |
| **TOTAL** | **22-38h** | **6-9 dias √∫teis** |

**Com dedica√ß√£o full-time**: 2 semanas
**Com dedica√ß√£o part-time**: 3-4 semanas

---

## ‚úÖ CRIT√âRIOS DE ACEITA√á√ÉO

### Antes de liberar para usu√°rios, TODAS as seguintes condi√ß√µes devem ser verdadeiras:

**Seguran√ßa:**
- [ ] Zero inst√¢ncias de fetch para localhost:7242
- [ ] Todas as credenciais rotacionadas
- [ ] .env n√£o est√° no git (verificado com git log)
- [ ] RLS ativo em todas as tabelas
- [ ] RLS testado (usu√°rio B n√£o v√™ dados de usu√°rio A)
- [ ] Autentica√ß√£o obrigat√≥ria (JWT) em todas as rotas
- [ ] Webhook com valida√ß√£o de signature
- [ ] Uploads validados (MIME type, tamanho, dimens√µes)
- [ ] Anti-SSRF implementado

**Qualidade:**
- [ ] Todos os testes passando (unit + integration + security)
- [ ] C√≥digo sem warnings cr√≠ticos do ESLint
- [ ] Logs n√£o cont√©m dados sens√≠veis
- [ ] Rate limiting ativo e testado

**Operacional:**
- [ ] Deploy em staging bem-sucedido
- [ ] Teste manual com 2 usu√°rios reais
- [ ] Health check passando
- [ ] Monitoring configurado (logs, erros)
- [ ] Documenta√ß√£o atualizada

**Compliance:**
- [ ] LGPD: dados isolados por usu√°rio (RLS)
- [ ] LGPD: sem vazamento de dados sens√≠veis
- [ ] Secrets management correto
- [ ] Audit trail de a√ß√µes cr√≠ticas

---

## üÜò CONTATO E SUPORTE

Se precisar de ajuda durante a implementa√ß√£o:

1. **Para cada vulnerabilidade**, execute os scripts de verifica√ß√£o
2. **Para cada corre√ß√£o**, execute os testes automatizados
3. **Antes de deploy**, execute checklist completo
4. **Em caso de d√∫vida**, priorize seguran√ßa sobre funcionalidade

---

## üìö REFER√äNCIAS

- OWASP Top 10: https://owasp.org/www-project-top-ten/
- Supabase RLS: https://supabase.com/docs/guides/auth/row-level-security
- Evolution API Webhook: https://doc.evolution-api.com/v2/pt/integrate/webhook
- LGPD Brasil: http://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/l13709.htm
- Express Security: https://expressjs.com/en/advanced/best-practice-security.html

---

**Data de cria√ß√£o**: 2026-01-13
**√öltima atualiza√ß√£o**: 2026-01-13
**Status**: üü° EM PROGRESSO
**Pr√≥xima revis√£o**: Ap√≥s conclus√£o do Bloco 1
